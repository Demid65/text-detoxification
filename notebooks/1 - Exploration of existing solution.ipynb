{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff7aea0-5c0d-4c9a-8a06-1dbf7e0fab8a",
   "metadata": {},
   "source": [
    "## Exploration of existing solutions\n",
    "Given task is an example of text2text problem, for which there are a variety of models already developed. The most straight forward solution to solve the problem is to find existing text2text model and finetune it on the provided dataset.\n",
    "\n",
    "Exploring the internet, I have found a [general text2text model](https://huggingface.co/t5-small) which aims to be finetunable to different kinds of tasks. In the original [paper](https://jmlr.org/papers/volume21/20-074/20-074.pdf) Raffel et al. have tested the model on a variety of datasets and a variety of different tasks, some of which are more complicated that detoxificiation task. That means this model should be good enough for the task at hand.\n",
    "\n",
    "The model is available at HuggingFace and I'll be using their set of libraries for that model. They provide a framework for translation tasks, so I'll use their [example training pipeline](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cbbcd5-6d36-47c3-a685-957953fdc75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>detoxified</th>\n",
       "      <th>tox_score</th>\n",
       "      <th>detox_score</th>\n",
       "      <th>similarity</th>\n",
       "      <th>length_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              toxic  \\\n",
       "0   0  if Alkar floods her with her mental waste, it ...   \n",
       "1   1                        you're becoming disgusting.   \n",
       "2   2                      well, we can spare your life.   \n",
       "3   3                       monkey, you have to wake up.   \n",
       "4   4                         I have orders to kill her.   \n",
       "\n",
       "                                          detoxified  tox_score  detox_score  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   0.981983     0.014195   \n",
       "1                          Now you're getting nasty.   0.999039     0.065473   \n",
       "2           Well, we could spare your life, for one.   0.985068     0.213313   \n",
       "3          Ah! Monkey, you've got to snap out of it.   0.994215     0.053362   \n",
       "4                   I've got orders to put her down.   0.999348     0.009402   \n",
       "\n",
       "   similarity  length_diff  \n",
       "0    0.785171     0.010309  \n",
       "1    0.749687     0.071429  \n",
       "2    0.919051     0.268293  \n",
       "3    0.664333     0.309524  \n",
       "4    0.726639     0.181818  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the cleaned dataset from previous notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347915fc-2bec-4490-a003-79c47e4b6061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c90d602-ce9f-48d9-ae46-c48318e5947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Demid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Haus ist wunderbar.\n"
     ]
    }
   ],
   "source": [
    "# test that it runs\n",
    "input_ids = tokenizer(\"translate English to German: The house is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "294b8ff6-532e-4ebd-82f4-f7528206c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NUM_VAL = 50000\n",
    "NUM_TEST = 50000\n",
    "\n",
    "df_text = df[['toxic','detoxified']].rename(columns={'toxic':'input','detoxified':'target'})\n",
    "train, val = train_test_split(df_text, test_size=NUM_VAL / len(df_text), random_state=42)\n",
    "train, test = train_test_split(train, test_size=NUM_TEST / len(train), random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train.to_dict(orient='list'))\n",
    "val_dataset = Dataset.from_dict(val.to_dict(orient='list'))\n",
    "test_dataset = Dataset.from_dict(test.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0947ed-7f4e-47c6-b636-c5cd60e0561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the dataset\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples['input']\n",
    "    targets = examples['target']\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eae634d-61d2-4730-8073-cd0146fa5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e80149596ac49ebb070bd04315e47a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/477777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Demid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af38bb396d784b8f963eba859a237b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b63c1e30cf4ffbb9c95dd7a0683825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed = train_dataset.map(preprocess_function, batched=True)\n",
    "val_processed = val_dataset.map(preprocess_function, batched=True)\n",
    "# test_processed = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cabde0a-00ad-4f4c-8a80-487e89bf3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training arguments\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "batch_size = 16\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"T5-Small-finetuned-detoxification\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, # set to True if you have CUDA, False if CUDA is not available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78915c16-5ac4-413d-b3a8-62f1514c368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data collator to pad the inputs and labels\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aefe082e-a0ea-4eac-b56d-8c961cc8c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Demid\\AppData\\Local\\Temp\\ipykernel_21756\\3458202905.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\") # using the metric from the example\n"
     ]
    }
   ],
   "source": [
    "# set up the metrics for the training process.\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"sacrebleu\") # using the metric from the example\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "339eb2be-2eda-4f20-bfa9-c07f27a0b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the trainer itself\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_processed,\n",
    "    eval_dataset=val_processed,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aac500-529f-44d8-a44e-992986d0de41",
   "metadata": {},
   "source": [
    "My laptop is not really capable of running the training, so it would be done in colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe7ea8-5de3-4c20-88ff-0978fe06d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the thing. That would take some time.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d69c7b-5a71-42e5-b04d-c6f2dc6f70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "trainer.save_model('T5Small-detoxification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a665c1ef-d5dc-4650-8b0c-a3c8fdeaf181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the model from file\n",
    "tokenizer_trained = T5Tokenizer.from_pretrained(\"T5Small-detoxification\")\n",
    "model_trained = T5ForConditionalGeneration.from_pretrained('T5Small-detoxification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cc37c77-0260-4ed8-bf23-065b80022280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>result</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so far, I have only planned to kill the Theban...</td>\n",
       "      <td>I only planned to kill the Thebans, and he org...</td>\n",
       "      <td>I have only planned and organized the killing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What the fuck are you gonna do, huh?</td>\n",
       "      <td>what are you going to do, huh?</td>\n",
       "      <td>what are you gonna do with me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Or that thing that chopped you up like little ...</td>\n",
       "      <td>or that thing that smashed you like a little p...</td>\n",
       "      <td>and the thing that cut you in slices like cutl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shut up, I'm thinking aloud.</td>\n",
       "      <td>I'm thinking loud.</td>\n",
       "      <td>shut up, I'm thinking out loud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A reliable source from inside Palmer's campaig...</td>\n",
       "      <td>a reliable source from Palmer's campaign... co...</td>\n",
       "      <td>a source inside Senator Palmer's campaign earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you have terrible communication skills.</td>\n",
       "      <td>You have terrible communication skills.</td>\n",
       "      <td>You have terrible communication skills. I do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I desire to catch her with the magic she pursu...</td>\n",
       "      <td>I want to catch her with the magic she pursues...</td>\n",
       "      <td>I want to catch her with the magic she craves,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Where in the fuck do you expect me to go?</td>\n",
       "      <td>where do you expect me to go?</td>\n",
       "      <td>where do you want me to go?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leeches. ...put that new boxtroll to work.</td>\n",
       "      <td>...put this new boxtroll to work.</td>\n",
       "      <td>the leeches.... to bring the new Shataturan to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How the hell do you set a catapult?</td>\n",
       "      <td>how do you set a catapult?</td>\n",
       "      <td>how the hell does a catapult be prepared?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I made you in the record store the minute I sa...</td>\n",
       "      <td>I made you in the record store the minute I sa...</td>\n",
       "      <td>I figured you through the record store.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shit, sorry.</td>\n",
       "      <td>sorry.</td>\n",
       "      <td>I'm sorry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It's right out of their brains.</td>\n",
       "      <td>it's right out of their brains.</td>\n",
       "      <td>it's right out of their heads.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>you want to be on the street where they can ki...</td>\n",
       "      <td>You want to be on the street where they can ki...</td>\n",
       "      <td>Putting yourself out where you could get killed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>now they bleed my guts, and they'll bleed to d...</td>\n",
       "      <td>Now they bleed my guts, and they bleed to death.</td>\n",
       "      <td>Now my guts bleed and theyâ€™ll always bleed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F... F...</td>\n",
       "      <td>F... F... F...</td>\n",
       "      <td>F... -What?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I know what over easy mean, goddamn it.</td>\n",
       "      <td>I know what it's all about, a little bit.</td>\n",
       "      <td>I know what it means to be soft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I'm surprised you didn't wanna go to Mumbai ju...</td>\n",
       "      <td>I'm surprised you didn't want to go to Mumbai ...</td>\n",
       "      <td>I'm surprised you didn't want to go to Mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I want him cold and dead, without blood in his...</td>\n",
       "      <td>I want him cold and dead, without blood in his...</td>\n",
       "      <td>and the dead, without the blood flowing throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"he's a traitor,\" Estraven told me, \"but I ask...</td>\n",
       "      <td>\"He's a traitor,\" Estraven told me, \"but I ask...</td>\n",
       "      <td>\"He is that,\" said Estraven, \"but I asked too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yeah, and the reason it's slippery out there, ...</td>\n",
       "      <td>and the reason it's slippery out there, that's...</td>\n",
       "      <td>yeah, and the reason why it's sliding is the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I hated her for that, and I still hate her.</td>\n",
       "      <td>I hated her for that, and I still hate her.</td>\n",
       "      <td>I hated her for that, and I still do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I am banished from all vampires under penalty ...</td>\n",
       "      <td>I'm banished from all vampires under the penal...</td>\n",
       "      <td>no vampire can be associated with me under thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Looks like a goddamn war zone.</td>\n",
       "      <td>looks like a war zone.</td>\n",
       "      <td>it looks like a war zone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>you'll stand or I'll cut you up!</td>\n",
       "      <td>You stand or I'll cut you up!</td>\n",
       "      <td>You stay in park or I will break you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I'm sick of you, Jonesy!</td>\n",
       "      <td>I'm sick of you, Jonesy!</td>\n",
       "      <td>I've had enough of you, Jonesy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>they'll take their little tweezers and stab yo...</td>\n",
       "      <td>They'll take their little tweezers and stab yo...</td>\n",
       "      <td>They get their little tweezers out and they're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I would say: Go to hell, Gillotina ... but giv...</td>\n",
       "      <td>I would say: Go to hell, Gillotina... but give...</td>\n",
       "      <td>I'd tell you to go somewhere, Gillotine... but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Killing a child in an immortal soul.</td>\n",
       "      <td>a child in an immortal soul.</td>\n",
       "      <td>she killed a child with his immortal soul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I have a brickfoot on my ass!</td>\n",
       "      <td>I have a brickfoot on my face!</td>\n",
       "      <td>I've got barnacles on my tuchus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>His shoulders slumped, and the spear fell from...</td>\n",
       "      <td>his shoulders slid, and the spear fell from hi...</td>\n",
       "      <td>his shoulders dropped, and the spear fell out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I'm a fool, whether I say yes or no no no.</td>\n",
       "      <td>I'm a fool, whether I say yes or no.</td>\n",
       "      <td>I'm crazy to say yes or no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>if you think I'm gonna kill someone just becau...</td>\n",
       "      <td>If you think I'm gonna kill someone just becau...</td>\n",
       "      <td>If you think I'm going to hurt someone just be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Smart as shit and still learning.</td>\n",
       "      <td>smart and still learning.</td>\n",
       "      <td>smart as a fox and still learning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>And, traitors that they are, they then let the...</td>\n",
       "      <td>and, the traitors that they are, they let thei...</td>\n",
       "      <td>and then, the traitors, for they are nothing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I'm fucking his wife.</td>\n",
       "      <td>I'm gonna be his wife.</td>\n",
       "      <td>I was banging his wife.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Get back to your fuckin' tribe before you get ...</td>\n",
       "      <td>get back to your tribe before you get hurt.</td>\n",
       "      <td>no? Go back to your before you get hurt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Neither of them had any fucking right to ask m...</td>\n",
       "      <td>neither of them had any right to ask me a thin...</td>\n",
       "      <td>none of them had the right to ask me about it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I know! I've heard quite enough about your sex...</td>\n",
       "      <td>I've heard quite enough about your sexual life...</td>\n",
       "      <td>I've heard it before in one day...... about yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Other trolls looked down on him because he cam...</td>\n",
       "      <td>other trolls looked at him because he came fro...</td>\n",
       "      <td>the other trolls looked at him scornfully, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>who's he calling a hooker?</td>\n",
       "      <td>Who's calling a hooker?</td>\n",
       "      <td>Who's she calling a ho?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I'm sorry but your father is a real wimp!</td>\n",
       "      <td>I'm sorry, but your father is a real snazzy!</td>\n",
       "      <td>okay, I'm sorry, but your father is really weird.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I know it's you leaving this place a pigsty.</td>\n",
       "      <td>I know you're leaving this place a pig.</td>\n",
       "      <td>I know you're the one who's leaving the pigsty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>he tensed in his foot and brushed the hooker, ...</td>\n",
       "      <td>He tensed in his foot and brushed the hooker, ...</td>\n",
       "      <td>He braced his legs and feet, pressing the cabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I'd be damned if I had to drink it.</td>\n",
       "      <td>I'd be damned if I had to drink it.</td>\n",
       "      <td>I'd be grouchy, too... if I had to drink that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>probably suicide.</td>\n",
       "      <td>It's probably suicide.</td>\n",
       "      <td>It was probably suicide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>You'il be weak as a kitten for at least an hour.</td>\n",
       "      <td>you'll be weak as a kitten for at least an hour.</td>\n",
       "      <td>you'll be weak as a kitten for at least anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>he's the traitor.</td>\n",
       "      <td>He's the traitor.</td>\n",
       "      <td>He's our mole.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>but don't kill me.</td>\n",
       "      <td>But don't kill me.</td>\n",
       "      <td>But don't embarrass me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>it must be, he thought, that his mind was occu...</td>\n",
       "      <td>It must be, he thought, that his mind was occu...</td>\n",
       "      <td>It's because their minds are so often involved...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  \\\n",
       "0   so far, I have only planned to kill the Theban...   \n",
       "1                What the fuck are you gonna do, huh?   \n",
       "2   Or that thing that chopped you up like little ...   \n",
       "3                        Shut up, I'm thinking aloud.   \n",
       "4   A reliable source from inside Palmer's campaig...   \n",
       "5             you have terrible communication skills.   \n",
       "6   I desire to catch her with the magic she pursu...   \n",
       "7           Where in the fuck do you expect me to go?   \n",
       "8          Leeches. ...put that new boxtroll to work.   \n",
       "9                 How the hell do you set a catapult?   \n",
       "10  I made you in the record store the minute I sa...   \n",
       "11                                       Shit, sorry.   \n",
       "12                    It's right out of their brains.   \n",
       "13  you want to be on the street where they can ki...   \n",
       "14  now they bleed my guts, and they'll bleed to d...   \n",
       "15                                          F... F...   \n",
       "16            I know what over easy mean, goddamn it.   \n",
       "17  I'm surprised you didn't wanna go to Mumbai ju...   \n",
       "18  I want him cold and dead, without blood in his...   \n",
       "19  \"he's a traitor,\" Estraven told me, \"but I ask...   \n",
       "20  Yeah, and the reason it's slippery out there, ...   \n",
       "21        I hated her for that, and I still hate her.   \n",
       "22  I am banished from all vampires under penalty ...   \n",
       "23                     Looks like a goddamn war zone.   \n",
       "24                   you'll stand or I'll cut you up!   \n",
       "25                           I'm sick of you, Jonesy!   \n",
       "26  they'll take their little tweezers and stab yo...   \n",
       "27  I would say: Go to hell, Gillotina ... but giv...   \n",
       "28               Killing a child in an immortal soul.   \n",
       "29                      I have a brickfoot on my ass!   \n",
       "30  His shoulders slumped, and the spear fell from...   \n",
       "31         I'm a fool, whether I say yes or no no no.   \n",
       "32  if you think I'm gonna kill someone just becau...   \n",
       "33                  Smart as shit and still learning.   \n",
       "34  And, traitors that they are, they then let the...   \n",
       "35                              I'm fucking his wife.   \n",
       "36  Get back to your fuckin' tribe before you get ...   \n",
       "37  Neither of them had any fucking right to ask m...   \n",
       "38  I know! I've heard quite enough about your sex...   \n",
       "39  Other trolls looked down on him because he cam...   \n",
       "40                         who's he calling a hooker?   \n",
       "41          I'm sorry but your father is a real wimp!   \n",
       "42       I know it's you leaving this place a pigsty.   \n",
       "43  he tensed in his foot and brushed the hooker, ...   \n",
       "44                I'd be damned if I had to drink it.   \n",
       "45                                  probably suicide.   \n",
       "46   You'il be weak as a kitten for at least an hour.   \n",
       "47                                  he's the traitor.   \n",
       "48                                 but don't kill me.   \n",
       "49  it must be, he thought, that his mind was occu...   \n",
       "\n",
       "                                               result  \\\n",
       "0   I only planned to kill the Thebans, and he org...   \n",
       "1                      what are you going to do, huh?   \n",
       "2   or that thing that smashed you like a little p...   \n",
       "3                                  I'm thinking loud.   \n",
       "4   a reliable source from Palmer's campaign... co...   \n",
       "5             You have terrible communication skills.   \n",
       "6   I want to catch her with the magic she pursues...   \n",
       "7                       where do you expect me to go?   \n",
       "8                   ...put this new boxtroll to work.   \n",
       "9                          how do you set a catapult?   \n",
       "10  I made you in the record store the minute I sa...   \n",
       "11                                             sorry.   \n",
       "12                    it's right out of their brains.   \n",
       "13  You want to be on the street where they can ki...   \n",
       "14   Now they bleed my guts, and they bleed to death.   \n",
       "15                                     F... F... F...   \n",
       "16          I know what it's all about, a little bit.   \n",
       "17  I'm surprised you didn't want to go to Mumbai ...   \n",
       "18  I want him cold and dead, without blood in his...   \n",
       "19  \"He's a traitor,\" Estraven told me, \"but I ask...   \n",
       "20  and the reason it's slippery out there, that's...   \n",
       "21        I hated her for that, and I still hate her.   \n",
       "22  I'm banished from all vampires under the penal...   \n",
       "23                             looks like a war zone.   \n",
       "24                      You stand or I'll cut you up!   \n",
       "25                           I'm sick of you, Jonesy!   \n",
       "26  They'll take their little tweezers and stab yo...   \n",
       "27  I would say: Go to hell, Gillotina... but give...   \n",
       "28                       a child in an immortal soul.   \n",
       "29                     I have a brickfoot on my face!   \n",
       "30  his shoulders slid, and the spear fell from hi...   \n",
       "31               I'm a fool, whether I say yes or no.   \n",
       "32  If you think I'm gonna kill someone just becau...   \n",
       "33                          smart and still learning.   \n",
       "34  and, the traitors that they are, they let thei...   \n",
       "35                             I'm gonna be his wife.   \n",
       "36        get back to your tribe before you get hurt.   \n",
       "37  neither of them had any right to ask me a thin...   \n",
       "38  I've heard quite enough about your sexual life...   \n",
       "39  other trolls looked at him because he came fro...   \n",
       "40                            Who's calling a hooker?   \n",
       "41       I'm sorry, but your father is a real snazzy!   \n",
       "42            I know you're leaving this place a pig.   \n",
       "43  He tensed in his foot and brushed the hooker, ...   \n",
       "44                I'd be damned if I had to drink it.   \n",
       "45                             It's probably suicide.   \n",
       "46   you'll be weak as a kitten for at least an hour.   \n",
       "47                                  He's the traitor.   \n",
       "48                                 But don't kill me.   \n",
       "49  It must be, he thought, that his mind was occu...   \n",
       "\n",
       "                                               target  \n",
       "0   I have only planned and organized the killing ...  \n",
       "1                      what are you gonna do with me?  \n",
       "2   and the thing that cut you in slices like cutl...  \n",
       "3                      shut up, I'm thinking out loud  \n",
       "4   a source inside Senator Palmer's campaign earl...  \n",
       "5       You have terrible communication skills. I do?  \n",
       "6   I want to catch her with the magic she craves,...  \n",
       "7                         where do you want me to go?  \n",
       "8   the leeches.... to bring the new Shataturan to...  \n",
       "9           how the hell does a catapult be prepared?  \n",
       "10            I figured you through the record store.  \n",
       "11                                         I'm sorry.  \n",
       "12                     it's right out of their heads.  \n",
       "13   Putting yourself out where you could get killed.  \n",
       "14        Now my guts bleed and theyâ€™ll always bleed.  \n",
       "15                                        F... -What?  \n",
       "16                   I know what it means to be soft.  \n",
       "17  I'm surprised you didn't want to go to Mumbai ...  \n",
       "18  and the dead, without the blood flowing throug...  \n",
       "19  \"He is that,\" said Estraven, \"but I asked too ...  \n",
       "20  yeah, and the reason why it's sliding is the l...  \n",
       "21              I hated her for that, and I still do.  \n",
       "22  no vampire can be associated with me under thr...  \n",
       "23                          it looks like a war zone.  \n",
       "24              You stay in park or I will break you!  \n",
       "25                    I've had enough of you, Jonesy.  \n",
       "26  They get their little tweezers out and they're...  \n",
       "27  I'd tell you to go somewhere, Gillotine... but...  \n",
       "28         she killed a child with his immortal soul.  \n",
       "29                   I've got barnacles on my tuchus.  \n",
       "30  his shoulders dropped, and the spear fell out ...  \n",
       "31                      I'm crazy to say yes or no...  \n",
       "32  If you think I'm going to hurt someone just be...  \n",
       "33                 smart as a fox and still learning.  \n",
       "34  and then, the traitors, for they are nothing b...  \n",
       "35                            I was banging his wife.  \n",
       "36           no? Go back to your before you get hurt.  \n",
       "37  none of them had the right to ask me about it,...  \n",
       "38  I've heard it before in one day...... about yo...  \n",
       "39  the other trolls looked at him scornfully, for...  \n",
       "40                            Who's she calling a ho?  \n",
       "41  okay, I'm sorry, but your father is really weird.  \n",
       "42    I know you're the one who's leaving the pigsty.  \n",
       "43  He braced his legs and feet, pressing the cabi...  \n",
       "44     I'd be grouchy, too... if I had to drink that.  \n",
       "45                           It was probably suicide.  \n",
       "46  you'll be weak as a kitten for at least anothe...  \n",
       "47                                     He's our mole.  \n",
       "48                            But don't embarrass me.  \n",
       "49  It's because their minds are so often involved...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if it is working on a part of test dataset\n",
    "input = []\n",
    "result = [] \n",
    "target = []\n",
    "N = 50\n",
    "\n",
    "for i in range(N):\n",
    "    input_ids = tokenizer_trained(test_dataset['input'][i], return_tensors=\"pt\").input_ids\n",
    "    outputs = model_trained.generate(input_ids, max_new_tokens = 100)\n",
    "    input.append(test_dataset['input'][i])\n",
    "    result.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    target.append(test_dataset['target'][i])\n",
    "\n",
    "pd.DataFrame.from_dict({'input': input, 'result': result, 'target': target}).head(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18b4e6-dfdc-4a9b-860d-868df954f229",
   "metadata": {},
   "source": [
    "As you can see, the model has shown some performance in detoxifying provided sentences. It is cleary capable of filtering swear words and doing some paraphrasing. It is very hesitant to make drastic changes to the text, and avoids removing words like 'kill', 'damned' and 'hell'. Some of the shorter and more agressvive sentences however are butchered just like the original dataset. Eg: I'm fucking his wife. -> I'm gonna be his wife.\n",
    "\n",
    "Regardless, the method is working, and it is the matter of tweaking to make it work. Increasing learning rate or number of epochs or adding a prefix could help improve the model performance. Or perhaps trying another model..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
